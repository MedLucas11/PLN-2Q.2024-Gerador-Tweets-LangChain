{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PcCTmXAl8Acl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Langchain in Chains: Google Search**\n",
        "###Gerador de tweets automatizado com LLMs\n",
        "---"
      ],
      "metadata": {
        "id": "IDcMDwFnfeD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Objetivo**\n",
        "---\n",
        "Vamos criar um gerador automático de tweets, utilizando como base um assunto qualquer de nossa escolha, para isso vamos utilizar o ***Google Serper API***, uma API que permite recuperar resultados de uma pesquisa no Google:\n",
        "\n",
        "<center><img src='https://cdn.prod.website-files.com/659415b46df8ea43c3877776/65b7f02e3e78f985c9b5b108_serper-homepage.jpeg'></center>\n",
        "\n",
        "Além disso vamos utilizar o LangChain para facilitar a implementação, juntamente com os LLMs Cohere para realizar embeddings e Gemini para geração dos tweets\n",
        "\n"
      ],
      "metadata": {
        "id": "-WwAJU52gy9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Metodologia**\n",
        "---\n",
        "Seguimos os métodos presentes no artigo escolhido<sup>[1]</sup>, com algumas diferenças para poder utilizar LLMs gratuitos, já que o artigo utiliza OpenAI. Por conta dessa mudança de LLM algumas partes do código ficaram diferentes do artigo original, mas o resultado final é o mesmo, os passos seguidos são:\n",
        "\n",
        "#### 1. Fazer o download das bibliotecas necessárias\n",
        "\n",
        "#### 2. Setar as chaves de API que iremos utilizar\n",
        "  \n",
        "#### 3. Definir uma função que irá realizar a busca no Google, de acordo com um assunto passado como entrada\n",
        "\n",
        "#### 4. Definir uma função que a partir dos resultados da busca retorna uma lista de 3 URLs mais relevantes\n",
        "\n",
        "#### 5. Definir a função que irá separar os textos das URLs em blocos e realizar os embeddings, retornando um objeto ***vectorstore*** com FAISS\n",
        "\n",
        "#### 6. Definir a função que irá gerar os tweets, fazendo uma busca por similaridade entre a query que fizemos no Google e o ***vectorstore*** criado no passo 5, juntando tudo em um único documento e criando os tweets utilizando a inteligência artificial\n",
        "\n"
      ],
      "metadata": {
        "id": "kTKwSL3NjSmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FAISS (Facebook AI Similarity Search)**\n",
        "---\n",
        "<center><img src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*i7BwsiaZ71mCuq12enDJtA.jpeg'></center>\n",
        "\n",
        "Como dito acima, vamos criar um ***vectorstore*** com FAISS para poder realizar uma busca por similaridade depois, vamos entender melhor o que é isso.\n",
        "\n",
        "FAISS é uma biblioteca desenvolvida pela Meta AI, projetada especifamente para lidar com pesquisas de similaridade de forma eficiente, o que é útil para lidar com grandes conjuntos de dados.\n",
        "\n",
        "Ele pode ser utilizado para criar um índice e realizar pesquisas com grande velocidade e eficiência de memória.\n",
        "\n",
        "O FAISS agiliza as pesquisas de vizinhos mais próximos indexando vetores usando algoritmos sofisticados como:\n",
        "\n",
        "1. **K-means clustering**: Esse algoritmo divide os dados em clusters, o que ajuda a restringir o espaço de pesquisa, concentrando-se nos clusters mais relevantes.\n",
        "\n",
        "2. **Quantização de produto (PQ)**: O PQ comprime os vetores em códigos mais curtos, reduzindo significativamente o uso da memória e acelerando a pesquisa sem uma grande queda de precisão\n",
        "\n",
        "3. **Quantização otimizada de produtos (OPQ)**: Uma versão aprimorada do PQ, o OPQ gira os dados para se ajustar melhor à grade de quantização, melhorando a precisação de vetores compactados.\n",
        "\n",
        "\n",
        "### **Casos de uso do FAISS**\n",
        "Por ser muito versátil e eficiente, o FAISS é ideal para uma variedade de aplicações de diferente tipos como:\n",
        "\n",
        "- Sistemas de Recomendação\n",
        "- Pesquisa de imagens e vídeos\n",
        "- Detecção de anomalias\n",
        "- Recuperação de informações (Utilizado neste projeto!)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hu9paRTDuyYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementação**\n",
        "---"
      ],
      "metadata": {
        "id": "UTuCJCQX52G3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1º passo:\n",
        "Instalar as bibliotecas necessárias e importar o que vai ser utilizado:"
      ],
      "metadata": {
        "id": "b3dpmlQS66ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-cohere\n",
        "!pip install -qU langchain-google-genai\n",
        "!pip install -qU unstructured\n",
        "!pip install -qU faiss-cpu\n",
        "!pip install -qU faiss-gpu\n",
        "!pip install -qU langchain\n",
        "!pip install -qU beautifulsoup4"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_oJOqrideDhK"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "from langchain_cohere import CohereEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.utilities import GoogleSerperAPIWrapper\n",
        "from langchain import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "from bs4 import BeautifulSoup\n",
        "from ast import literal_eval\n",
        "from google.colab import userdata\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "tIHRZZDYfV2q"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2º passo:\n",
        "Setar as chaves para utilizar os serviços das APIs, também definir o modelo que irá realizar os embeddings:"
      ],
      "metadata": {
        "id": "RxxQ2iOy7cqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = userdata.get(\"COHERE_API_KEY\")\n",
        "os.environ[\"SERPER_API_KEY\"] = userdata.get(\"SERPER_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "yJLZoWiVfr82"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = CohereEmbeddings(model=\"embed-english-v3.0\")"
      ],
      "metadata": {
        "id": "wrTrzsCMgW1d"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3º passo:\n",
        "\n",
        "Definindo a função que realiza a busca baseado em um assunto de entrada:"
      ],
      "metadata": {
        "id": "PcCTmXAl8Acl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A função possui um parâmetro \"query\" que será a nossa busca desejada\n",
        "def search(query: str) -> dict:\n",
        "\n",
        "  # Instaciamos o objeto GoogleSerperAPIWrapper, que irá realizar a busca baseada na query\n",
        "  # k será a quantidade de resultados, gl o país de origem das páginas e hl a língua\n",
        "  search = GoogleSerperAPIWrapper(k=10, gl='br', hl='pt-br', type=\"search\")\n",
        "  response = search.results(query)\n",
        "\n",
        "  # Por fim retornamos os resultados\n",
        "  return response"
      ],
      "metadata": {
        "id": "d7w4pc82gcUW"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui definimos nossa busca e utilizamos a função criada para\n",
        "query = \"Últimas notícias do futebol brasileiro\"\n",
        "search_results = search(query)\n",
        "search_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOQQrkc6grx8",
        "outputId": "f393ca4e-c7dc-4c15-a120-3d77eae9c42c"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'searchParameters': {'q': 'Últimas notícias do futebol brasileiro',\n",
              "  'gl': 'br',\n",
              "  'hl': 'pt-br',\n",
              "  'type': 'search',\n",
              "  'num': 10,\n",
              "  'engine': 'google'},\n",
              " 'organic': [{'title': 'Futebol | ge - Globo Esporte',\n",
              "   'link': 'https://ge.globo.com/futebol/',\n",
              "   'snippet': 'Acompanhe as notícias de Futebol no ge.globo.',\n",
              "   'sitelinks': [{'title': 'Futebol internacional',\n",
              "     'link': 'https://ge.globo.com/futebol/futebol-internacional/'},\n",
              "    {'title': 'Brasileiro Feminino',\n",
              "     'link': 'https://ge.globo.com/futebol/futebol-feminino/brasileiro-feminino/'},\n",
              "    {'title': 'Futebol português',\n",
              "     'link': 'https://ge.globo.com/futebol/futebol-internacional/futebol-portugues/'},\n",
              "    {'title': 'Flamengo',\n",
              "     'link': 'https://ge.globo.com/futebol/times/flamengo/'}],\n",
              "   'position': 1},\n",
              "  {'title': 'Futebol - UOL Esporte',\n",
              "   'link': 'https://www.uol.com.br/esporte/futebol/ultimas/',\n",
              "   'snippet': 'Acompanhe no UOL Esporte as Últimas notícias, fotos, vídeos, dicas e competições de futebol e provas de outras modalidades.',\n",
              "   'position': 2},\n",
              "  {'title': 'Futebol Nacional | Notícias, jogos e resultados - LANCE!',\n",
              "   'link': 'https://www.lance.com.br/futebol-nacional',\n",
              "   'snippet': 'No LANCE, você fica por dentro de tudo sobre Futebol Nacional. Acompanhe as últimas notícias, resultados e próximos jogos. Clique e não perca nada!',\n",
              "   'position': 3},\n",
              "  {'title': 'Tudo sobre: Futebol brasileiro - CNN Brasil',\n",
              "   'link': 'https://www.cnnbrasil.com.br/tudo-sobre/futebol-brasileiro/',\n",
              "   'snippet': 'Tudo sobre Futebol brasileiro. Conteúdos, notícias, entrevistas, breaking news e mais. Acompanhe na CNN Brasil!',\n",
              "   'position': 4},\n",
              "  {'title': 'Campeonato Brasileiro - Notícias, Estatísticas e Resultados - ESPN',\n",
              "   'link': 'https://www.espn.com.br/futebol/liga/_/nome/bra.1',\n",
              "   'snippet': 'Siga tudo sobre Campeonato Brasileiro. Notícias, classificação, estatísticas e mais na ESPN.',\n",
              "   'position': 5},\n",
              "  {'title': 'ge.globo - É esporte sempre',\n",
              "   'link': 'https://ge.globo.com/',\n",
              "   'snippet': 'No ge.globo você encontra a melhor cobertura sobre o Futebol e Outros Esportes, no Brasil e no Mundo: Notícias, Vídeos, Tabelas, Agenda e muito mais.',\n",
              "   'sitelinks': [{'title': 'Brasileirão Série A',\n",
              "     'link': 'https://ge.globo.com/futebol/brasileirao-serie-a/'},\n",
              "    {'title': 'Brasileiro Feminino',\n",
              "     'link': 'https://ge.globo.com/futebol/futebol-feminino/brasileiro-feminino/'},\n",
              "    {'title': 'Futebol italiano',\n",
              "     'link': 'https://ge.globo.com/futebol/futebol-internacional/futebol-italiano/'},\n",
              "    {'title': 'Flamengo',\n",
              "     'link': 'https://ge.globo.com/futebol/times/flamengo/'}],\n",
              "   'position': 6},\n",
              "  {'title': '90min - As últimas notícias de futebol, contratações e opinião do ...',\n",
              "   'link': 'https://www.90min.com/pt-BR',\n",
              "   'snippet': '90min é a maior plataforma de futebol do mundo, reunindo as últimas notícias, rumores de transferências, jogos, resultados, opinião, vídeos e muito ...',\n",
              "   'sitelinks': [{'title': 'Notícias de Futebol',\n",
              "     'link': 'https://www.90min.com/pt-BR/categories/noticias-futebol'},\n",
              "    {'title': 'Futebol internacional',\n",
              "     'link': 'https://www.90min.com/pt-BR/categories/futebol-internacional'},\n",
              "    {'title': 'Brasileiro Série B',\n",
              "     'link': 'https://www.90min.com/pt-BR/leagues/brasileiro-serie-b'},\n",
              "    {'title': 'Brasileirão Série A',\n",
              "     'link': 'https://www.90min.com/pt-BR/leagues/brasileiro-serie-a'}],\n",
              "   'position': 7},\n",
              "  {'title': 'Mercado da Bola - Transferências da série A do Brasileirão - LANCE!',\n",
              "   'link': 'https://www.lance.com.br/mercado-da-bola/',\n",
              "   'snippet': 'Acompanhe o vai e vem entre os clubes de futebol em 2024, janela de transferências e todas as informações relevantes sobre os jogadores. Destaque. Últimas ...',\n",
              "   'sitelinks': [{'title': 'Flamengo busca contratação...',\n",
              "     'link': 'https://www.lance.com.br/flamengo/flamengo-busca-contratacao-de-lucas-paqueta-na-janela-de-transferencias-entenda.html'},\n",
              "    {'title': 'Após a saída de João Palhinha',\n",
              "     'link': 'https://www.lance.com.br/futebol-internacional/bayern-acerta-com-joao-palhinha-e-fulham-volta-a-manifestar-interesse-em-volante-brasileiro.html'},\n",
              "    {'title': 'Corinthians',\n",
              "     'link': 'https://www.lance.com.br/mercado-da-bola/estatisticas/corinthians'}],\n",
              "   'position': 8},\n",
              "  {'title': 'FutebolBrasileiro | Notícias - Somos Fanáticos',\n",
              "   'link': 'https://somosfanaticos.fans/br/futebolbrasileiro',\n",
              "   'snippet': 'Últimas noticias de FutebolBrasileiro. Conheça todas as novidades relacionadas a FutebolBrasileiro sobre somosfanaticos.fans/br.',\n",
              "   'position': 9},\n",
              "  {'title': 'Campeonato Brasileiro Série A: Notícias e Jogos do Brasileirão | Terra',\n",
              "   'link': 'https://www.terra.com.br/esportes/futebol/brasileiro-serie-a/',\n",
              "   'snippet': 'Confira todas as informações sobre o Brasileirão Série A: tabela do campeonato, classificação e resultados dos jogos, notícias, fotos, vídeos e mais.',\n",
              "   'sitelinks': [{'title': 'Classificação e Tabela',\n",
              "     'link': 'https://www.terra.com.br/esportes/futebol/brasileiro-serie-a/tabela/'},\n",
              "    {'title': 'Série B',\n",
              "     'link': 'https://www.terra.com.br/esportes/futebol/brasileiro-serie-b/'},\n",
              "    {'title': 'Neto crava favorito para...',\n",
              "     'link': 'https://www.terra.com.br/esportes/futebol/brasileiro-serie-a/neto-crava-favorito-para-vencer-o-brasileirao-clube-nao-leva-o-titulo-ha-mais-de-20-anos,0c6d3e931b0214384055f3ded708aac5e9iods96.html'}],\n",
              "   'position': 10}],\n",
              " 'peopleAlsoAsk': [{'question': 'Quais são as últimas notícias sobre futebol?',\n",
              "   'snippet': 'Cristiano Ronaldo ironiza o próprio time e não participa de premiação na Supercopa Saudita. ...\\nItuano quebra três tabus em dois jogos e ganha fôlego contra o rebaixamento na Série B. ...\\nVc Escala: com Almada e trio de volantes, torcida do Botafogo quer força máxima contra o Flamengo.',\n",
              "   'title': 'Futebol | ge - Globo Esporte',\n",
              "   'link': 'https://ge.globo.com/futebol/'},\n",
              "  {'question': 'Quais são as notícias do esporte de hoje?',\n",
              "   'snippet': 'ÚLTIMAS NOTÍCIAS DE: ESPORTES\\nTitular do Atlético-MG, meia Matías Zaracho passará por cirurgia. ...\\nBrighton x Manchester United: horário e onde assistir ao jogo da Premier League. ...\\nTati Weston-Webb é vice em Fiji e garante vaga no WSL Finals. ...\\nSantos x Amazonas: horário e onde assistir ao jogo da Série B. ...\\nDéjà vu?',\n",
              "   'title': 'Esportes - Confira notícias da Editoria - CNN Brasil',\n",
              "   'link': 'https://www.cnnbrasil.com.br/esportes/ultimas-noticias/'},\n",
              "  {'question': 'Qual o melhor site de notícias de futebol?',\n",
              "   'snippet': 'Bem-vindo ao OneFootball. Sua melhor fonte de notícias de futebol, jogos ao vivo, resultados, destaques e muito mais!',\n",
              "   'title': 'OneFootball: inicio',\n",
              "   'link': 'https://onefootball.com/pt-br/inicio'},\n",
              "  {'question': 'Quais são os jogos de hoje pelo Brasil?',\n",
              "   'snippet': 'ESPORTE NA BAND\\nAtlético-MG x Fluminense: placar ao vivo, escalações, lances, gols e mais.\\nPalmeiras x Cuiabá: placar ao vivo, escalações, lances, gols e mais.\\nItuano x Goiás: placar ao vivo, escalações, lances, gols e mais.\\nSantos x Amazonas: placar ao vivo, escalações, lances, gols e mais.',\n",
              "   'title': 'Jogos de hoje - Veja horários e partidas - Band - UOL',\n",
              "   'link': 'https://www.band.uol.com.br/esportes/futebol/jogos-de-hoje'}],\n",
              " 'relatedSearches': [{'query': 'Últimas notícias sobre futebol'},\n",
              "  {'query': 'Notícias do futebol brasileiro mercado da bola'},\n",
              "  {'query': 'Notícias futebol europeu'},\n",
              "  {'query': 'Notícias do futebol internacional'},\n",
              "  {'query': 'Últimas notícias sobre futebol Flamengo'},\n",
              "  {'query': 'Tudo sobre futebol brasileiro'},\n",
              "  {'query': 'Google notícias futebol'},\n",
              "  {'query': 'Jogos de hoje ao vivo'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4º passo:\n",
        "\n",
        "Definir uma função que, a partir dos resultados da pesquisa, retorna apenas 3 URLs que são consideradas mais relevantes:"
      ],
      "metadata": {
        "id": "hPtYxR9OACF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passamos como parâmetro os resultados da pesquisa assim como a \"query\" que foi feita\n",
        "def extract_top_article_urls(search_results: dict, query: str) -> list:\n",
        "\n",
        "  # Primeiros tranformamos os resultados em uma string, para poder passar no template para Inteligência Artificial\n",
        "  string = json.dumps(search_results)\n",
        "\n",
        "  # Definimos o modelo que será utilizado para nossa tarefa\n",
        "  modelo = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.8)\n",
        "\n",
        "  # Escrevemos um template de prompt, ele irá analisar os resultados obtidos na nossa pesquisa e filtrar pelos 3 que ele considerar mais relevantes baseado na nossa pesquisa inicial, retornando uma lista de URLs\n",
        "  prompt_template_str = \"\"\"\n",
        "  You are a world-class sports journalist with a keen eye for identifying content that drives views and interactions on Twitter. Your expertise lies in finding the most engaging, relevant, and timely sports articles.\n",
        "\n",
        "  QUERY RESPONSE: {string}\n",
        "\n",
        "  Above is the list of search results for the query \"{query}\".\n",
        "\n",
        "  Your task is to meticulously select the top 3 articles from the list that will generate the highest engagement on Twitter. Return ONLY a LIST (ARRAY) of the URLs. Exclude any other information. Ensure the articles are fresh and not outdated. If the file or URL is invalid, return www.google.com.\n",
        "  \"\"\"\n",
        "\n",
        "  # Criamos a cadeia que irá executar o template com os parâmetros necessários, juntamente com o modelo que será utilizado\n",
        "  prompt_template = PromptTemplate(input_variables=[\"string\", \"query\"], template=prompt_template_str)\n",
        "  selection_chain =  prompt_template | modelo\n",
        "\n",
        "  # Executamos a cadeia\n",
        "  response = selection_chain.invoke({\"string\": string, \"query\": query})\n",
        "\n",
        "  # Como a resposta que é retornada vem em uma String deste tipo \" ```python[\"url1\", \"url2\", \"url3\"]``` \", fazemos um tratamento para ficar no formato de lista de fato\n",
        "  urls = response.content\n",
        "  urls = urls.replace(\"`\", \"\")\n",
        "  urls = urls.replace(\"json\", \"\")\n",
        "\n",
        "  # Após o tratamento ele ainda é uma String, por isso utilizamos essa função para transformar uma String diretamente em Lista\n",
        "  urls_list = literal_eval(urls)\n",
        "\n",
        "  return urls_list"
      ],
      "metadata": {
        "id": "cZNnKG4ohcC7"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urls_list = extract_top_article_urls(search_results, query)\n",
        "print(urls_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U36MF8GwinK-",
        "outputId": "9eff7117-5f54-4ed8-addc-bf595c02be07"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['https://ge.globo.com/futebol/', 'https://www.uol.com.br/esporte/futebol/ultimas/', 'https://www.lance.com.br/futebol-nacional']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5º passo:\n",
        "Definir funções para extrair os textos das URLs e para separar os textos, criando o ***vectorstore***:"
      ],
      "metadata": {
        "id": "WwF8aGNrMAsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Essa primeira função serve para recuperar o conteúdo das URLs\n",
        "def fetch_text_from_url(url):\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_5_0) AppleWebKit/536.1 (KHTML, like Gecko) Chrome/58.0.849.0 Safari/536.1'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    return soup.get_text()\n",
        "\n",
        "\n",
        "# Toda essa próxima parte foi feita com auxílio do ChatGPT. Utilizando os embeddings do Cohere diversos erros aconteciam ao escrever o código igual ao do artigo, mais especificamente ao tentar instaciar o objeto FAISS.\n",
        "# Por isso fomos implementando as sugestões feitas pela IA para tentar contornar os erros e obter o resultado esperado.\n",
        "\n",
        "# Criamos uma classe que simula um armazenamento de documentos que é suportado pelo índice FAISS, oferecendo duas funções principais 'get' e 'search'\n",
        "class DummyDocStore:\n",
        "    def __init__(self, documents):\n",
        "        self.documents = documents\n",
        "\n",
        "    # Recupera um documento específico com base em seu ID, verificando se o ID está dentro dos limites da lista de documentos\n",
        "    def get(self, doc_id):\n",
        "        if 0 <= doc_id < len(self.documents):\n",
        "            return self.documents[doc_id]\n",
        "        else:\n",
        "            raise ValueError(f\"Document ID {doc_id} is out of bounds.\")\n",
        "\n",
        "    # Recupera documentos com base em uma lista de IDs.\n",
        "    def search(self, doc_ids):\n",
        "\n",
        "        # Verifica se 'doc_ids' é um inteiro (o que indica apenas um documento)\n",
        "        if isinstance(doc_ids, int):\n",
        "            return self.get(doc_ids)  # Retorna um único documento\n",
        "\n",
        "        # Se 'doc_ids' for uma lista, retorna uma lista de documentos correspondente\n",
        "        elif isinstance(doc_ids, list):\n",
        "            return [self.get(doc_id) for doc_id in doc_ids]\n",
        "        else:\n",
        "            raise ValueError(\"doc_ids should be an int or list of ints.\")\n",
        "\n",
        "\n",
        "# Função para carregar e processar os conteúdos das URLs, dividir o texto em chunks, criar os embeddings e construir um índice FAISS para busca\n",
        "def split_content_from_urls(urls_list: list) -> FAISS:\n",
        "\n",
        "  # Adicionamos os textos brutos das URLs em uma lista\n",
        "  texts = [fetch_text_from_url(url) for url in urls_list]\n",
        "\n",
        "  # Criamos objetos 'Document' a partir dos textos\n",
        "  documents = [Document(page_content=text) for text in texts]\n",
        "\n",
        "  # Definimos o splitter que irá dividir os textos. Esse método faz o split de forma recursiva, e tenta manter 'pedaços' relacionados próximos um do outro\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "  # Iniciamos listas vazias que irão armazenar os chunks de texto e os IDs dos documentos originais\n",
        "  split_documents = []\n",
        "  doc_ids = []\n",
        "\n",
        "  for i, doc in enumerate(documents):\n",
        "      chunks = text_splitter.split_text(doc.page_content) # Divide o conteúdo de cada documento em chunks\n",
        "      split_documents.extend(chunks) # Adiciona os chunks gerados à lista 'split_documents'\n",
        "      doc_ids.extend([i] * len(chunks)) # Associa o ID do documento original para cada chunk gerado a partir dele. Isso permite mapear cada chunk de volta ao documento original\n",
        "\n",
        "  # Cria embeddings para cada chunk de texto usando o modelo de embeddigns do Cohere\n",
        "  chunk_embeddings = embeddings.embed_documents(split_documents)\n",
        "\n",
        "  # Converte os embeddings para um array numpy de ponto flutuante, que é necessário para criar o índice FAISS\n",
        "  chunk_embeddings = np.array(chunk_embeddings, dtype=np.float32)\n",
        "\n",
        "  # Colocamos a dimensão dos nossos embeddings em uma variável (número de colunas)\n",
        "  dim = chunk_embeddings.shape[1]\n",
        "\n",
        "  # Criamos um índice FAISS utilizando a métrica de distância L2 (distância euclidiana) para comparação\n",
        "  faiss_index = faiss.IndexFlatL2(dim)\n",
        "\n",
        "  # Adicionamos os embeddings ao nosso índice FAISS\n",
        "  faiss_index.add(chunk_embeddings)\n",
        "\n",
        "  # Utilizamos a classe que criamos para armazenar os documentos originais\n",
        "  docstore = DummyDocStore(documents)\n",
        "\n",
        "  # Criamos um dicionário que mapeia os IDs dos chunks de texto para os IDs dos documentos originais\n",
        "  index_to_docstore_id = {i: doc_ids[i] for i in range(len(split_documents))}\n",
        "\n",
        "  # Instanciamos o objeto FAISS, com todos os parâmetros necessários\n",
        "  faiss_store = FAISS(index=faiss_index, docstore=docstore, index_to_docstore_id=index_to_docstore_id, embedding_function=embeddings)\n",
        "\n",
        "  return faiss_store"
      ],
      "metadata": {
        "id": "VKI-Lpw0p_Kd"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = split_content_from_urls(urls_list)\n",
        "print(type(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RISnlyJV66GP",
        "outputId": "d08df55a-f237-4af9-d342-84514703c4f8"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_community.vectorstores.faiss.FAISS'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6º passo:\n",
        "Definir a função que irá gerar os tweets:"
      ],
      "metadata": {
        "id": "io4kChHrOvep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finalmente, definimos a função que irá gerar os tweets, baseado no índice FAISS para buscar documentos semelhantes, a 'query' que fizemos e o número 'k' de documentos semelhantes que desejamos recuperar\n",
        "def generate_engaging_tweets(faiss_index: FAISS, query: str, k: int=3) -> str:\n",
        "\n",
        "    # Busca os documentos mais semelhantes com a 'query' que foi feita\n",
        "    similar_docs = faiss_index.similarity_search(query, k=k)\n",
        "\n",
        "    # Verifica se 'similar_docs' é uma lista ou apenas um documento\n",
        "    if isinstance(similar_docs, list):\n",
        "        aggregated_content = \" \".join([doc.page_content for doc in similar_docs if doc is not None])\n",
        "    else:\n",
        "        aggregated_content = similar_docs.page_content if similar_docs is not None else \"\"\n",
        "\n",
        "    # Caso ocorra erro pelo tamanho do conteúdo, determine um limite para não ultrapassar a cota do LLM\n",
        "    #if len(aggregated_content) > 10000:\n",
        "      #aggregated_content = aggregated_content[:10000]\n",
        "\n",
        "\n",
        "    # Definimos o modelo que será utilizado, o prompt, e criamos a chain que irá gerar os tweets\n",
        "    modelo = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.8)\n",
        "\n",
        "    prompt_template_str = \"\"\"\n",
        "        {docs}\n",
        "        As a world-class sports journalist, you will summarize the text above to create engaging tweets around the topic \"{query}\".\n",
        "        These tweets will be posted on Twitter to drive high engagement.\n",
        "        Write them in brazilian portuguese.\n",
        "\n",
        "        Please follow all of the following guidelines:\n",
        "        1. Ensure the content is engaging and informative with good data.\n",
        "        2. Keep the tweets concise, fitting within Twitter's character limit.\n",
        "        3. Address the topic \"{query}\" very well and stay on point.\n",
        "        4. Make sure the content is high quality and informative.\n",
        "        5. Write in a way that is easy to read, digest, and understand.\n",
        "        6. Provide actionable insights and advice, including resources and links if necessary.\n",
        "\n",
        "        TWEET:\n",
        "        \"\"\"\n",
        "\n",
        "    prompt_template = PromptTemplate(input_variables=[\"docs\", \"query\"], template=prompt_template_str)\n",
        "\n",
        "    tweet_summarizer_chain = prompt_template | modelo\n",
        "\n",
        "    tweets = tweet_summarizer_chain.invoke({\"docs\":aggregated_content, \"query\":query})\n",
        "\n",
        "    return tweets.content"
      ],
      "metadata": {
        "id": "r7_jhNTA_js9"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = generate_engaging_tweets(data, query)\n",
        "Markdown(tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "mqKwa3sY__Xj",
        "outputId": "0b3c8321-ea1d-4a46-873a-d929f1c1601e"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Últimas notícias do futebol brasileiro:\n\n**Tweet 1:** 🚨 O Inter não perde para o Cruzeiro no Beira-Rio há mais de 10 anos! 😮 Será que o tabu se mantém? #Inter #Cruzeiro #Grenal #Brasileirão\n\n**Tweet 2:** 🏥 Tite teve alta do hospital após internação por arritmia cardíaca. 🙏 Desejamos melhoras ao técnico! #Tite #SeleçãoBrasileira #ForçaTite\n\n**Tweet 3:** 🔥 Flamengo faz proposta por Alex Sandro, ex-Juventus! 💰 Será que o Mengão vai repatriar o lateral? #Flamengo #AlexSandro #MercadoDaBola\n\n**Tweet 4:** ⚽️  O Corinthians vendeu Wesley para a Arábia Saudita! 🇸🇦 O jogador será companheiro de Cristiano Ronaldo! #Corinthians #Wesley #CristianoRonaldo\n\n**Tweet 5:** 🏆 Libertadores: cariocas complicam datas das quartas de final. 🤔 CBF busca alternativas! #Libertadores #Flamengo #Fluminense #CBF \n\n**Tweet 6:** 🏟️  Jogo do Fluminense hoje: saiba onde assistir, horário e escalações! ➡️ [link para o artigo] #Fluminense #Brasileirão #OndeAssistir\n\n**Tweet 7:** 📊 Convocação para Seleção comprova acerto de Luiz Henrique ao escolher o Botafogo! #Botafogo #LuizHenrique #SeleçãoBrasileira\n\n**Tweet 8:** 🚨 Santos terá novidade em todas as áreas do campo contra o Amazonas! #Santos #SérieB #FutebolBrasileiro\n"
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Refêrencias:**\n",
        "\n",
        "[1] Artigo Medium: https://medium.com/@okanyenigun/langchain-in-chains-28-google-search-af86874bd29c\n",
        "\n",
        "[2] O que é Faiss (Facebook AI Similarity Search)?: https://www.datacamp.com/pt/blog/faiss-facebook-ai-similarity-search"
      ],
      "metadata": {
        "id": "y5djmQwZvMnZ"
      }
    }
  ]
}